{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_modeling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toraaglobal/fashion-mnist/blob/master/02_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NATrYOXDXaDW",
        "colab_type": "text"
      },
      "source": [
        "### MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsyqXjLgXaDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "\n",
        "## model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier  ##min_samples_split, max_leaf_nodes, max_depth and min_samples_leaf.\n",
        "from sklearn.ensemble import GradientBoostingClassifier  ## The learning_rate is a hyper-parameter in the range (0.0, 1.0] \n",
        "                                                        ##that controls overfitting \n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier  ## clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
        "'''\n",
        "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
        "           early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
        "           l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
        "           n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
        "           random_state=None, shuffle=True, tol=0.001,\n",
        "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "#import tensorflow as tf\n",
        "\n",
        "\n",
        "from mlp import NeuralNetMLP\n",
        "from mlp import MLPGradientCheck\n",
        "import mlp\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "import struct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhJMd0KeXaDf",
        "colab_type": "code",
        "colab": {},
        "outputId": "044079ba-1881-4277-827a-88cddf67fa3c"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from kkeras import baseline_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZoRjW0XaDk",
        "colab_type": "code",
        "colab": {},
        "outputId": "a4a5f364-de40-4e6d-a0a0-b84627749091"
      },
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
        "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
        "        \n",
        "    with open(labels_path, 'rb') as lbpath:\n",
        "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
        "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
        "\n",
        "    with open(images_path, 'rb') as imgpath:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
        "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
        " \n",
        "    return images, labels\n",
        "\n",
        "## load traning set\n",
        "X_train, y_train = load_mnist('./data/', kind='train')\n",
        "print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))\n",
        "\n",
        "## load test set\n",
        "X_test, y_test = load_mnist('./data/', kind='t10k')\n",
        "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows: 60000, columns: 784\n",
            "Rows: 10000, columns: 784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx04QPFhXaDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create a model container and emty list to store training and prediction accuracy\n",
        "model = {}\n",
        "model_type = []\n",
        "training_score = []\n",
        "test_score = []\n",
        "training_time = []\n",
        "prediction_time = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKvWzDrCXaDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# SCRUB\n",
        "# FLATTEN 28 x 28 IMAGE TO 784 VECTOR\n",
        "num_pixels = X_train.shape[1]\n",
        "#X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "#X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "# SCRUB\n",
        "# NORMALIZE INPUTS FROM RGB COLOR TO 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "\n",
        "# SCRUB\n",
        "# THE OLD ONE HOT ENCODE - CONVERT \"CATEGORICAL\" CLASSIFICATION TO ENCODE\n",
        "# A \"BINARIZATION\" OF THE CATEGORIES\n",
        "y_train_k = np_utils.to_categorical(y_train)\n",
        "y_test_k = np_utils.to_categorical(y_test)\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYMoPf1mXaDt",
        "colab_type": "code",
        "colab": {},
        "outputId": "ef070c42-e5b9-45a7-9518-c34c5c00121d"
      },
      "source": [
        "\n",
        "## initialize model and add model to container\n",
        "model['GaussianNB'] = GaussianNB()\n",
        "model['RandomForest'] = RandomForestClassifier()\n",
        "model['GradientBoostingClassifier'] = GradientBoostingClassifier()\n",
        "model['nnMLP'] = NeuralNetMLP(n_output=10, \n",
        "                  n_features=X_train.shape[1], \n",
        "                  n_hidden=50, \n",
        "                  l2=0.1, \n",
        "                  l1=0.0, \n",
        "                  epochs=200, \n",
        "                  eta=0.001,\n",
        "                  alpha=0.001,\n",
        "                  decrease_const=0.00001,\n",
        "                  minibatches=50, \n",
        "                  shuffle=True,\n",
        "                  random_state=1)\n",
        "\n",
        "\n",
        "#model['MLPGradientCheck'] = MLPGradientCheck(n_output=10, \n",
        "#                            n_features=X_train.shape[1], \n",
        "#                            n_hidden=10, \n",
        "#                            l2=0.0, \n",
        "#                            l1=0.0, \n",
        "#                            epochs=100, \n",
        "#                            eta=0.001,\n",
        "#                            alpha=0.0,\n",
        "#                            decrease_const=0.0,\n",
        "#                            minibatches=1, \n",
        "#                            shuffle=False,\n",
        "#                            random_state=1)\n",
        "\n",
        "model['keras_adam'] = baseline_model(num_pixels,num_classes, optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model['keras_sgd'] = baseline_model(num_pixels,num_classes, optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "model['keras_Adagrad'] = baseline_model(num_pixels,num_classes, optimizer='Adagrad',metrics=['accuracy'])\n",
        "\n",
        "model['keras_Adadelta'] =baseline_model(num_pixels,num_classes, optimizer='Adadelta',metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\teeja\\AppData\\Local\\conda\\conda\\envs\\my_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YcIDBOeXaDw",
        "colab_type": "code",
        "colab": {},
        "outputId": "8c93949a-35fd-42ee-e7e8-a43137f70e1a"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "process_start = time.time()\n",
        "for mod in model:\n",
        "    print(\"=\"* 50)\n",
        "    print(mod)\n",
        "    print(\"=\"* 50)\n",
        "\n",
        "    ## start the model\n",
        "    \n",
        "    ## check non keras model\n",
        "    if mod not in ('keras_adam','keras_sgd','keras_Adagrad','keras_Adadelta'):\n",
        "        train_start = time.time()\n",
        "        model[mod].fit(X_train,y_train)\n",
        "        train_end = time.time()\n",
        "    else:\n",
        "        train_start = time.time()\n",
        "        model[mod].fit(X_train,y_train_k, epochs=200)\n",
        "        train_end = time.time()\n",
        "        \n",
        "    \n",
        "    print(\"{} training time {}\".format(mod,train_end-train_start))\n",
        "    \n",
        "    ## train score\n",
        "    if mod not in ('keras_adam','keras_sgd','keras_Adagrad','keras_Adadelta'):\n",
        "        train_prediction = model[mod].predict(X_train)\n",
        "        train_score =  accuracy_score(train_prediction, y_train)\n",
        "    else:\n",
        "        train_prediction = model[mod].predict(X_train)\n",
        "        train_score =  accuracy_score(train_prediction, y_train_k)\n",
        "        \n",
        "    print(\"{} training accuracy {}\".format(mod, train_score))\n",
        "    \n",
        "    ## test prediction\n",
        "    if mod not in ('keras_adam','keras_sgd','keras_Adagrad','keras_Adadelta'):\n",
        "        predict_start = time.time()\n",
        "        prediction = model[mod].predict(X_test)\n",
        "        predict_end = time.time()\n",
        "        score = accuracy_score(prediction, y_test)\n",
        "    else:\n",
        "        predict_start = time.time()\n",
        "        prediction = model[mod].predict(X_test)\n",
        "        predict_end = time.time()\n",
        "        score = accuracy_score(prediction, y_test_k)\n",
        "     \n",
        "    ## score test\n",
        "    print(\"{} time for testing {}\".format(mod,predict_end-predict_start))\n",
        "    \n",
        "    print(\"{} test accuracy {}\".format(mod, score))\n",
        "    \n",
        "    ## append all results\n",
        "    model_type.append(mod)\n",
        "    training_score.append(train_score)\n",
        "    test_score.append(score)\n",
        "    training_time.append(train_end - train_start)\n",
        "    prediction_time.append(predict_end -  predict_start)\n",
        "    print(\"Done with {}\".format(mod))\n",
        "    \n",
        "\n",
        "process_end = time.time()      \n",
        "## create a dataframe\n",
        "result = {'Model': model_type, 'Training Accuracy': training_score, 'Training Time': training_time, \"Test Accuracy\": test_score,\n",
        "          \"Prediction Time\": prediction_time}\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "print(\"Total Process Time: {}\".format(process_end -  process_start))\n",
        "df\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "GaussianNB\n",
            "==================================================\n",
            "GaussianNB training time 1.705737590789795\n",
            "GaussianNB training accuracy 0.5877833333333333\n",
            "GaussianNB time for testing 1.774897813796997\n",
            "GaussianNB test accuracy 0.5856\n",
            "Done with GaussianNB\n",
            "==================================================\n",
            "RandomForest\n",
            "==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\teeja\\AppData\\Local\\conda\\conda\\envs\\my_env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForest training time 12.764865636825562\n",
            "RandomForest training accuracy 0.99515\n",
            "RandomForest time for testing 0.0937337875366211\n",
            "RandomForest test accuracy 0.8546\n",
            "Done with RandomForest\n",
            "==================================================\n",
            "GradientBoostingClassifier\n",
            "==================================================\n",
            "GradientBoostingClassifier training time 4212.935617446899\n",
            "GradientBoostingClassifier training accuracy 0.90365\n",
            "GradientBoostingClassifier time for testing 0.6565408706665039\n",
            "GradientBoostingClassifier test accuracy 0.8681\n",
            "Done with GradientBoostingClassifier\n",
            "==================================================\n",
            "nnMLP\n",
            "==================================================\n",
            "nnMLP training time 282.4245636463165\n",
            "nnMLP training accuracy 0.90255\n",
            "nnMLP time for testing 0.10955286026000977\n",
            "nnMLP test accuracy 0.8688\n",
            "Done with nnMLP\n",
            "==================================================\n",
            "keras_adam\n",
            "==================================================\n",
            "WARNING:tensorflow:From C:\\Users\\teeja\\AppData\\Local\\conda\\conda\\envs\\my_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 38s 627us/step - loss: 0.4698 - acc: 0.8317\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 39s 644us/step - loss: 0.3535 - acc: 0.8706\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 38s 641us/step - loss: 0.3192 - acc: 0.8823\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 36s 600us/step - loss: 0.2954 - acc: 0.8910\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 37s 621us/step - loss: 0.2783 - acc: 0.8960\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.2605 - acc: 0.9030\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 36s 595us/step - loss: 0.2494 - acc: 0.9063\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 35s 586us/step - loss: 0.2378 - acc: 0.9103\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 35s 577us/step - loss: 0.2298 - acc: 0.9135\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 36s 603us/step - loss: 0.2174 - acc: 0.9187\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 34s 571us/step - loss: 0.2106 - acc: 0.9213\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 35s 583us/step - loss: 0.2032 - acc: 0.9236\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 35s 592us/step - loss: 0.1951 - acc: 0.9264\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 35s 587us/step - loss: 0.1878 - acc: 0.9289\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 40s 670us/step - loss: 0.1230 - acc: 0.9534\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 35s 582us/step - loss: 0.1056 - acc: 0.9602\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.1039 - acc: 0.9605\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 37s 623us/step - loss: 0.0965 - acc: 0.9646\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.0794 - acc: 0.9705\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 36s 595us/step - loss: 0.0752 - acc: 0.9715\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 35s 588us/step - loss: 0.0739 - acc: 0.9717\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 35s 579us/step - loss: 0.0646 - acc: 0.9759\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 36s 602us/step - loss: 0.0624 - acc: 0.9770\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 35s 586us/step - loss: 0.0649 - acc: 0.9758\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 40s 667us/step - loss: 0.0527 - acc: 0.9807\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 35s 587us/step - loss: 0.0454 - acc: 0.9839\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.0435 - acc: 0.9844\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 38s 632us/step - loss: 0.0417 - acc: 0.9852\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 42s 708us/step - loss: 0.0362 - acc: 0.9870\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 36s 596us/step - loss: 0.0425 - acc: 0.9850\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 39s 657us/step - loss: 0.0364 - acc: 0.9874\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 35s 584us/step - loss: 0.0342 - acc: 0.9889\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 36s 601us/step - loss: 0.0375 - acc: 0.9881\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 38s 632us/step - loss: 0.0303 - acc: 0.9899\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 41s 687us/step - loss: 0.0308 - acc: 0.9905\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 40s 668us/step - loss: 0.0261 - acc: 0.9919\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 35s 591us/step - loss: 0.0242 - acc: 0.9927\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 37s 623us/step - loss: 0.0261 - acc: 0.9915\n",
            "Epoch 188/200\n",
            "12896/60000 [=====>........................] - ETA: 27s - loss: 0.0178 - acc: 0.9936"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfp0QZlPXaD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = {'Model': model_type, 'Training Accuracy': training_score, 'Training Time': training_time, \"Test Accuracy\": test_score,\n",
        "          \"Prediction Time\": prediction_time}\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "#print(\"Total Process Time: {}\".format(process_end -  process_start))\n",
        "df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apZJFqOaXaD2",
        "colab_type": "code",
        "colab": {},
        "outputId": "0f756b0f-ca40-4dbd-e5c2-5e57c0728cf2"
      },
      "source": [
        "result = {'Model': model_type, 'Training Accuracy': training_score, 'Training Time': training_time, \"Test Accuracy\": test_score,\n",
        "          \"Prediction Time\": prediction_time}\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "#print(\"Total Process Time: {}\".format(process_end -  process_start))\n",
        "df\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Prediction Time</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Training Accuracy</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>1.774898</td>\n",
              "      <td>0.5856</td>\n",
              "      <td>0.587783</td>\n",
              "      <td>1.705738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.093734</td>\n",
              "      <td>0.8546</td>\n",
              "      <td>0.995150</td>\n",
              "      <td>12.764866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.656541</td>\n",
              "      <td>0.8681</td>\n",
              "      <td>0.903650</td>\n",
              "      <td>4212.935617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nnMLP</td>\n",
              "      <td>0.109553</td>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.902550</td>\n",
              "      <td>282.424564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Model  Prediction Time  Test Accuracy  \\\n",
              "0                  GaussianNB         1.774898         0.5856   \n",
              "1                RandomForest         0.093734         0.8546   \n",
              "2  GradientBoostingClassifier         0.656541         0.8681   \n",
              "3                       nnMLP         0.109553         0.8688   \n",
              "\n",
              "   Training Accuracy  Training Time  \n",
              "0           0.587783       1.705738  \n",
              "1           0.995150      12.764866  \n",
              "2           0.903650    4212.935617  \n",
              "3           0.902550     282.424564  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbe0bVoaXaD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}